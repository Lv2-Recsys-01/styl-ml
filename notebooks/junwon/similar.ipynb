{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfit_df = pd.read_csv('../../data/train-test/season_new_meta_22-23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the outfit_id column into a list of tuples (outfit_id, reporter)\n",
    "outfit_id_list = [(outfit_id) for outfit_id in outfit_df['outfit_id']]\n",
    "outfit_reporter_list = [(reporter) for reporter in outfit_df['reporter']]\n",
    "print(outfit_id_list)\n",
    "print(outfit_reporter_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade jpype1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jpype\n",
    "print(jpype.isJVMStarted()) #return False:not running or 0:running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "\n",
    "!apt-get install g++ openjdk-8-jdk python-dev python3-dev -y\n",
    "\n",
    "!pip3 install JPype1-py3\n",
    "\n",
    "!pip3 install konlpy\n",
    "\n",
    "!JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 꼬꼬마 형태소 분석기 초기화\n",
    "kkma = Kkma()\n",
    "\n",
    "# 문장을 형태소 단위로 분리하는 함수\n",
    "def tokenize(text):\n",
    "    return ' '.join(kkma.morphs(text))\n",
    "\n",
    "# 문장을 형태소 단위로 분리하여 벡터화\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize)\n",
    "tfidf_matrix = vectorizer.fit_transform(outfit_reporter_list)\n",
    "print(tfidf_matrix)\n",
    "# 문장들 간의 유사도 계산\n",
    "similarities = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# 결과 출력 with tqdm\n",
    "num_sentences = len(outfit_reporter_list)\n",
    "with tqdm(total=num_sentences*(num_sentences-1)//2) as pbar:\n",
    "    for i in range(len(outfit_reporter_list)):\n",
    "        for j in range(i + 1, len(outfit_reporter_list)):\n",
    "            similarity = similarities[i][j]\n",
    "            # print(f\"문장 {i+1}과 문장 {j+1}의 유사도: {similarity}\")\n",
    "            pbar.update(1)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ... Your code to calculate the similarities ...\n",
    "\n",
    "# Save the similarities to a file\n",
    "np.save('similarities.npy', similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the similarities from the file\n",
    "similarities = np.load('similarities.npy')\n",
    "\n",
    "# Now you can use the loaded similarities for further processing or analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities[1][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# ... (previous code)\n",
    "\n",
    "# Initialize a list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate over all items\n",
    "for sentence_idx in range(len(outfit_reporter_list)):\n",
    "    # Get the similarities for the specified item\n",
    "    similarities_for_sentence = similarities[sentence_idx]\n",
    "\n",
    "    # Sort the similarities in descending order and get the indices of the sorted similarities\n",
    "    sorted_indices = np.argsort(similarities_for_sentence)[::-1]\n",
    "\n",
    "    # Get the top 10 most similar item indices (excluding the original item)\n",
    "    top_10_indices = sorted_indices[1:11]\n",
    "\n",
    "    # Get the outfit_id for the current item\n",
    "    outfit_id = outfit_id_list[sentence_idx]\n",
    "\n",
    "    # Get the outfit_id for the top 10 most similar items\n",
    "    similar_outfits = [outfit_id_list[idx] for idx in top_10_indices]\n",
    "\n",
    "    # Append the data to the list\n",
    "    data.append([outfit_id, \"{\" + ','.join(map(str, similar_outfits)) + \"}\"])\n",
    "\n",
    "# Save the data to a CSV file\n",
    "csv_filename = 'similarwithkkma.csv'\n",
    "with open(csv_filename, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['outfit_id', 'similar_outfits'])\n",
    "    csv_writer.writerows(data)\n",
    "\n",
    "print(f\"Data saved to {csv_filename}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "\n",
    "outfit_ids = [86875,87482,87956,88613,87879,77980,87838,87101,88085,87060,86828]\n",
    "\n",
    "\n",
    "base_url = 'https://stylesjourney.com/detail/'\n",
    "\n",
    "for outfit_id in outfit_ids:\n",
    "    url = base_url + str(outfit_id)\n",
    "    webbrowser.open(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
