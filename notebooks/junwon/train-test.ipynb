{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#like_click, share\n",
    "data_path = '../data'\n",
    "like_click_path = os.path.join(data_path, 'like_click.csv')\n",
    "# share_path = os.path.join(data_path, 'click_share_musinsa_log.csv')\n",
    "# view\n",
    "view_image_path = os.path.join(data_path, 'view.csv')\n",
    "#outfit\n",
    "outfit_path = os.path.join(data_path, 'outfit.csv')\n",
    "\n",
    "like_click_df = pd.read_csv(like_click_path)\n",
    "# share_df = pd.read_csv(share_path)\n",
    "view_df = pd.read_csv(view_image_path)\n",
    "outfit_df = pd.read_csv(outfit_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#like_click데이터를 합침\n",
    "like_click_df = like_click_df.groupby(['session_id', 'outfit_id'], as_index=False).agg({\n",
    "    'like_type': lambda x: ', '.join(x.dropna()).strip() or np.nan,\n",
    "    'click_type': lambda x: ', '.join(x.dropna()).strip() or np.nan\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like_click_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#like:1 / click:2 / both:3\n",
    "like_click_df['implicit'] = np.where((~like_click_df['click_type'].isnull()) & (~like_click_df['like_type'].isnull()), 3,\n",
    "                                    np.where(~like_click_df['like_type'].isnull(), 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# like_click_df[like_click_df['implicit']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like_click_df = like_click_df[['session_id', 'outfit_id', 'implicit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like_click_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_df = view_df.drop_duplicates(subset=['session_id', 'outfit_id'], keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.concat([view_df, like_click_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.drop_duplicates(subset=['session_id', 'outfit_id'], keep='last', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df[concat_df['implicit']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'session_id' column in your DataFrame\n",
    "concat_df['session_id'] = label_encoder.fit_transform(concat_df['session_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to map implicit ratings to corresponding values\n",
    "def map_implicit_rating(implicit_rating):\n",
    "    if implicit_rating == 1:\n",
    "        return 0.9\n",
    "    elif implicit_rating == 2:\n",
    "        return 0.6\n",
    "    elif implicit_rating == 3:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return implicit_rating\n",
    "\n",
    "# Apply the mapping function to the 'implicit rating' column and store the result in the 'rating' column\n",
    "concat_df['rating'] = concat_df['implicit'].apply(map_implicit_rating)\n",
    "\n",
    "# Drop the 'implicit rating' column if needed\n",
    "concat_df.drop(columns=['implicit'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df['rating'] = concat_df['rating'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = concat_df[['session_id','outfit_id','rating']]\n",
    "train_path = \"../data/test.csv\"\n",
    "concat_df.to_csv(train_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame by 'session_id'\n",
    "grouped_df = concat_df.groupby('session_id')\n",
    "\n",
    "# Create a function to balance and extract samples from each group\n",
    "def balance_and_extract_samples(group):\n",
    "    non_zero_rows = group[group['rating'] != 0]\n",
    "    zero_rows = group[group['rating'] == 0]\n",
    "\n",
    "    # Calculate the target number of non-zero rows to achieve the 2:1 ratio\n",
    "    target_zero_count = int(len(non_zero_rows) * 2)\n",
    "\n",
    "    # If there are fewer non-zero rows than the target, use all of them\n",
    "    if len(zero_rows) <= target_zero_count:\n",
    "        zero_sample = zero_rows\n",
    "    else:\n",
    "        # Randomly sample 'target_non_zero_count' non-zero rows\n",
    "        zero_sample = zero_rows.sample(n=target_zero_count, random_state=42)\n",
    "\n",
    "    # Combine non-zero sample with zero rows\n",
    "    balanced_sample = pd.concat([zero_sample, non_zero_rows])\n",
    "\n",
    "    # Randomly shuffle the rows\n",
    "    balanced_sample = balanced_sample.sample(frac=1, random_state=42)\n",
    "\n",
    "    return balanced_sample\n",
    "\n",
    "# Apply the function to each 'session_id' group and combine the results\n",
    "balanced_sample_df = grouped_df.apply(balance_and_extract_samples)\n",
    "\n",
    "# Reset the index to convert 'session_id' back to a regular column\n",
    "balanced_sample_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Get the last 10 entries for each 'session_id' group as the test set\n",
    "test_set = balanced_sample_df.groupby('session_id').tail(3)\n",
    "\n",
    "# Drop the test set from the balanced_sample_df to get the training set\n",
    "train_set = balanced_sample_df.drop(test_set.index)\n",
    "\n",
    "# Save the test set to 'test.csv'\n",
    "test_set.to_csv('../data/train-test/test.csv', index=False)\n",
    "\n",
    "# Save the training set to 'train.csv'\n",
    "train_set.to_csv('../data/train-test/train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_sample_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
