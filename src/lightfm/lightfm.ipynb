{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightfm.data import Dataset\n",
    "from scipy.io import mmwrite\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df= pd.read_csv('../../data/train-test/implicit_data.csv')\n",
    "outfit_df = pd.read_csv('../../data/train-test/outfit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상호작용이 적은 유저 필터링\n",
    "\n",
    "# session_id를 기준으로 묶었을 때 각 그룹의 길이 구하기\n",
    "grouped_counts = rating_df.groupby('session_id').size()\n",
    "\n",
    "# 길이가 5 미만인 session_id를 삭제하기 위한 조건 생성\n",
    "session_ids_to_remove = grouped_counts[grouped_counts < 5].index\n",
    "\n",
    "# 조건에 해당하는 session_id를 삭제한 데이터프레임 생성\n",
    "filtered_rating_df = rating_df[~rating_df['session_id'].isin(session_ids_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id\n",
       "02bfeca8-0440-42df-bba7-adbdea393ef4     6\n",
       "033f88ff-2382-4742-a0a7-ca56b5c98571     7\n",
       "049025e9-7327-4fcf-8b5b-3b129d119e8c    15\n",
       "04a49069-ce63-4144-9eba-4c6a097281a0    43\n",
       "052efac5-ad8c-4acd-bc41-1be5f1e83d1f    46\n",
       "                                        ..\n",
       "f58e3ebc-f51f-4318-b1e5-cb22379ce91f    13\n",
       "f8dc0ea8-fc3a-435b-a93d-50c9f2d86396    11\n",
       "fa9c15f8-26ea-4caf-a1a7-e7988e35c9a8     5\n",
       "fb6abf78-226d-4a39-9fd3-9f3401091f06     6\n",
       "fe3b84c2-5dba-4788-bf69-cb7b1ea170f0    49\n",
       "Length: 124, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # session_id를 라벨 인코딩\n",
    "# label_encoder = LabelEncoder()\n",
    "# filtered_rating_df['session_id'] = label_encoder.fit_transform(filtered_rating_df['session_id'])\n",
    "filtered_rating_df.groupby('session_id').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>outfit_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7708c8e7-4292-4ff9-99b1-27be20427e42</td>\n",
       "      <td>83800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7708c8e7-4292-4ff9-99b1-27be20427e42</td>\n",
       "      <td>83791</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7708c8e7-4292-4ff9-99b1-27be20427e42</td>\n",
       "      <td>84029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7708c8e7-4292-4ff9-99b1-27be20427e42</td>\n",
       "      <td>83706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7708c8e7-4292-4ff9-99b1-27be20427e42</td>\n",
       "      <td>83988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>ea15b529-afa8-4e44-aacc-f725a6837d4a</td>\n",
       "      <td>85516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>1c55ce42-2c94-44a3-a1b3-b037c87662ab</td>\n",
       "      <td>83999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>8995a6e7-a51c-463e-949e-add908c64d4b</td>\n",
       "      <td>86011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>da05e137-0516-4fa9-8297-a7335b504352</td>\n",
       "      <td>73342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>da05e137-0516-4fa9-8297-a7335b504352</td>\n",
       "      <td>81307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                session_id  outfit_id  rating\n",
       "0     7708c8e7-4292-4ff9-99b1-27be20427e42      83800       1\n",
       "1     7708c8e7-4292-4ff9-99b1-27be20427e42      83791       1\n",
       "2     7708c8e7-4292-4ff9-99b1-27be20427e42      84029       1\n",
       "3     7708c8e7-4292-4ff9-99b1-27be20427e42      83706       1\n",
       "4     7708c8e7-4292-4ff9-99b1-27be20427e42      83988       1\n",
       "...                                    ...        ...     ...\n",
       "1693  ea15b529-afa8-4e44-aacc-f725a6837d4a      85516       1\n",
       "1694  1c55ce42-2c94-44a3-a1b3-b037c87662ab      83999       1\n",
       "1696  8995a6e7-a51c-463e-949e-add908c64d4b      86011       1\n",
       "1697  da05e137-0516-4fa9-8297-a7335b504352      73342       1\n",
       "1698  da05e137-0516-4fa9-8297-a7335b504352      81307       1\n",
       "\n",
       "[1460 rows x 3 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # 그래프 그리기\n",
    "# plt.hist(grouped_counts, bins=len(grouped_counts), edgecolor='black')\n",
    "# plt.xlabel('Size')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Histogram of Session Size')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저별로 랜덤하게 1개의 데이터를 추출하여 train과 test 데이터프레임 생성\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "for _, group in filtered_rating_df.groupby('session_id'):\n",
    "    if len(group) == 1:\n",
    "        # 유저에게 데이터가 1개인 경우, train에 포함\n",
    "        train_indices.append(group.index[0])\n",
    "    else:\n",
    "        # 랜덤하게 1개의 데이터를 test에 포함, 나머지는 train에 포함\n",
    "        random_index = np.random.choice(group.index)\n",
    "        test_indices.append(random_index)\n",
    "        train_indices.extend(group.index.drop(random_index))\n",
    "\n",
    "train_df = filtered_rating_df.loc[train_indices].reset_index(drop=True)\n",
    "test_df = filtered_rating_df.loc[test_indices].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['session_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['session_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id\n",
       "0178cc11-02c9-4c75-8089-9e8e1d9a31d5     1\n",
       "017a246a-3a3a-43f2-862b-732b3e078d8f     1\n",
       "02bfeca8-0440-42df-bba7-adbdea393ef4     6\n",
       "033f88ff-2382-4742-a0a7-ca56b5c98571     7\n",
       "049025e9-7327-4fcf-8b5b-3b129d119e8c    15\n",
       "                                        ..\n",
       "fa9c15f8-26ea-4caf-a1a7-e7988e35c9a8     5\n",
       "fb6abf78-226d-4a39-9fd3-9f3401091f06     6\n",
       "fb9c9692-1c50-4299-8d2c-5325d1577a90     1\n",
       "fbddf83e-dc26-4064-9848-d1a211ac69f1     1\n",
       "fe3b84c2-5dba-4788-bf69-cb7b1ea170f0    49\n",
       "Length: 229, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.groupby('session_id').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>outfit_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02bfeca8-0440-42df-bba7-adbdea393ef4</td>\n",
       "      <td>86535</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02bfeca8-0440-42df-bba7-adbdea393ef4</td>\n",
       "      <td>87736</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02bfeca8-0440-42df-bba7-adbdea393ef4</td>\n",
       "      <td>90119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02bfeca8-0440-42df-bba7-adbdea393ef4</td>\n",
       "      <td>83181</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02bfeca8-0440-42df-bba7-adbdea393ef4</td>\n",
       "      <td>90093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>fe3b84c2-5dba-4788-bf69-cb7b1ea170f0</td>\n",
       "      <td>82414</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>fe3b84c2-5dba-4788-bf69-cb7b1ea170f0</td>\n",
       "      <td>85081</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>fe3b84c2-5dba-4788-bf69-cb7b1ea170f0</td>\n",
       "      <td>85523</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>fe3b84c2-5dba-4788-bf69-cb7b1ea170f0</td>\n",
       "      <td>86709</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>fe3b84c2-5dba-4788-bf69-cb7b1ea170f0</td>\n",
       "      <td>83700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1336 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                session_id  outfit_id  rating\n",
       "0     02bfeca8-0440-42df-bba7-adbdea393ef4      86535       1\n",
       "1     02bfeca8-0440-42df-bba7-adbdea393ef4      87736       1\n",
       "2     02bfeca8-0440-42df-bba7-adbdea393ef4      90119       1\n",
       "3     02bfeca8-0440-42df-bba7-adbdea393ef4      83181       1\n",
       "4     02bfeca8-0440-42df-bba7-adbdea393ef4      90093       1\n",
       "...                                    ...        ...     ...\n",
       "1331  fe3b84c2-5dba-4788-bf69-cb7b1ea170f0      82414       1\n",
       "1332  fe3b84c2-5dba-4788-bf69-cb7b1ea170f0      85081       1\n",
       "1333  fe3b84c2-5dba-4788-bf69-cb7b1ea170f0      85523       1\n",
       "1334  fe3b84c2-5dba-4788-bf69-cb7b1ea170f0      86709       1\n",
       "1335  fe3b84c2-5dba-4788-bf69-cb7b1ea170f0      83700       1\n",
       "\n",
       "[1336 rows x 3 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outfit 후보군 만들기\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outfit_df = outfit_df[['outfit_id','reporter','gender','age','style','season', 'year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        23.0\n",
       "1        19.0\n",
       "2        22.0\n",
       "3        25.0\n",
       "4        24.0\n",
       "         ... \n",
       "10424    21.0\n",
       "10425    21.0\n",
       "10426    19.0\n",
       "10427    21.0\n",
       "10428    21.0\n",
       "Name: age, Length: 10429, dtype: float64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_age = int(outfit_df['age'].mean())\n",
    "outfit_df['age'].fillna(mean_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit -ALS MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: implicit in /opt/conda/envs/jun/lib/python3.9/site-packages (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/jun/lib/python3.9/site-packages (from implicit) (4.65.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/jun/lib/python3.9/site-packages (from implicit) (1.22.3)\n",
      "Requirement already satisfied: scipy>=0.16 in /opt/conda/envs/jun/lib/python3.9/site-packages (from implicit) (1.7.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install implicit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train_df['session_id'] = label_encoder.fit_transform(train_df['session_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      session_id  outfit_id  rating\n",
       " 0              0      86535       1\n",
       " 1              0      80776       1\n",
       " 2              0      90119       1\n",
       " 3              0      83181       1\n",
       " 4              0      90093       1\n",
       " ...          ...        ...     ...\n",
       " 1331         123      82414       1\n",
       " 1332         123      85081       1\n",
       " 1333         123      85523       1\n",
       " 1334         123      86709       1\n",
       " 1335         123      83700       1\n",
       " \n",
       " [1336 rows x 3 columns],\n",
       "                                session_id  outfit_id  rating\n",
       " 0    02bfeca8-0440-42df-bba7-adbdea393ef4      87736       1\n",
       " 1    033f88ff-2382-4742-a0a7-ca56b5c98571      83765       1\n",
       " 2    049025e9-7327-4fcf-8b5b-3b129d119e8c      80424       1\n",
       " 3    04a49069-ce63-4144-9eba-4c6a097281a0      78410       1\n",
       " 4    052efac5-ad8c-4acd-bc41-1be5f1e83d1f      83488       1\n",
       " ..                                    ...        ...     ...\n",
       " 119  f58e3ebc-f51f-4318-b1e5-cb22379ce91f      78826       1\n",
       " 120  f8dc0ea8-fc3a-435b-a93d-50c9f2d86396      82271       1\n",
       " 121  fa9c15f8-26ea-4caf-a1a7-e7988e35c9a8      80886       1\n",
       " 122  fb6abf78-226d-4a39-9fd3-9f3401091f06      80427       1\n",
       " 123  fe3b84c2-5dba-4788-bf69-cb7b1ea170f0      91211       1\n",
       " \n",
       " [124 rows x 3 columns])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id     124\n",
       "outfit_id     1190\n",
       "rating           1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9038752976834813"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1336/(124*1192)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "len() of unsized object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[149], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m num_users \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(users)\n\u001b[1;32m     22\u001b[0m num_items \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(items)\n\u001b[0;32m---> 23\u001b[0m user_item_matrix \u001b[39m=\u001b[39m coo_matrix((\u001b[39m0\u001b[39;49m, (rows, cols)), shape\u001b[39m=\u001b[39;49m(num_users, num_items))\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(user_item_matrix)\n\u001b[1;32m     26\u001b[0m user_item_matrix_csr \u001b[39m=\u001b[39m user_item_matrix\u001b[39m.\u001b[39mtocsr()\n",
      "File \u001b[0;32m/opt/conda/envs/jun/lib/python3.9/site-packages/scipy/sparse/coo.py:196\u001b[0m, in \u001b[0;36mcoo_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    194\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 196\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check()\n",
      "File \u001b[0;32m/opt/conda/envs/jun/lib/python3.9/site-packages/scipy/sparse/coo.py:281\u001b[0m, in \u001b[0;36mcoo_matrix._check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol, dtype\u001b[39m=\u001b[39midx_dtype)\n\u001b[1;32m    279\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m to_native(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n\u001b[0;32m--> 281\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnnz \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    282\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrow\u001b[39m.\u001b[39mmax() \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m    283\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mrow index exceeds matrix dimensions\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/jun/lib/python3.9/site-packages/scipy/sparse/base.py:246\u001b[0m, in \u001b[0;36mspmatrix.nnz\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    239\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnnz\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    240\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Number of stored values, including explicit zeros.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \n\u001b[1;32m    242\u001b[0m \u001b[39m    See also\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[39m    --------\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39m    count_nonzero : Number of non-zero entries\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgetnnz()\n",
      "File \u001b[0;32m/opt/conda/envs/jun/lib/python3.9/site-packages/scipy/sparse/coo.py:241\u001b[0m, in \u001b[0;36mcoo_matrix.getnnz\u001b[0;34m(self, axis)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetnnz\u001b[39m(\u001b[39mself\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    240\u001b[0m     \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m         nnz \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata)\n\u001b[1;32m    242\u001b[0m         \u001b[39mif\u001b[39;00m nnz \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrow) \u001b[39mor\u001b[39;00m nnz \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol):\n\u001b[1;32m    243\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mrow, column, and data array must all be the \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    244\u001b[0m                              \u001b[39m'\u001b[39m\u001b[39msame length\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: len() of unsized object"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import implicit\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# train_df와 test_df 데이터프레임을 합친 상호작용 데이터 프레임 생성\n",
    "interaction_data = pd.concat([train_df[['session_id', 'outfit_id']],\n",
    "                              test_df[['session_id', 'outfit_id']]])\n",
    "\n",
    "# 사용자와 아이템 ID 매핑\n",
    "users = list(interaction_data['session_id'].unique())\n",
    "items = list(interaction_data['outfit_id'].unique())\n",
    "user_to_idx = {user: idx for idx, user in enumerate(users)}\n",
    "item_to_idx = {item: idx for idx, item in enumerate(items)}\n",
    "\n",
    "# train_df 데이터를 사용하여 user_item_matrix 생성 (1로 할당)\n",
    "rows = [user_to_idx[user] for user in train_df['session_id']]\n",
    "cols = [item_to_idx[item] for item in train_df['outfit_id']]\n",
    "values = [1] * len(rows)\n",
    "\n",
    "# 모든 사용자에 대해 1개의 행을 가지도록 user_item_matrix 생성\n",
    "num_users = len(users)\n",
    "num_items = len(items)\n",
    "user_item_matrix = coo_matrix((values, (rows, cols)), shape=(num_users, num_items))\n",
    "print(user_item_matrix)\n",
    "\n",
    "user_item_matrix_csr = user_item_matrix.tocsr()\n",
    "\n",
    "# ALS MF 모델 초기화\n",
    "model = implicit.als.AlternatingLeastSquares(factors=50, iterations=10)\n",
    "\n",
    "# 모델 학습 (희소 행렬 입력)\n",
    "model.fit(user_item_matrix)\n",
    "\n",
    "# 특정 사용자에 대한 아이템 추천 (예시로 사용자 1에 대해 추천)\n",
    "user_id = 100  # 실제 사용자 ID로 변경해야 합니다.\n",
    "user_idx = user_to_idx[user_id]\n",
    "\n",
    "# 이미 상호작용한 아이템은 필터링하고, N개의 아이템을 추천합니다.\n",
    "N = 5\n",
    "recommended_items = model.recommend(user_idx, user_item_matrix_csr, N=N, filter_already_liked_items=True)\n",
    "\n",
    "# 추천된 아이템 출력\n",
    "print(f\"사용자 ID: {user_id}\")\n",
    "for item_idx, score in recommended_items:\n",
    "    item_id = items[item_idx]\n",
    "    print(f'아이템 ID: {item_id}  Score: {score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새로운 사용자 ID: 101\n",
      "추천된 아이템 ID: 0  평점: 1\n",
      "추천된 아이템 ID: 1  평점: 1\n",
      "추천된 아이템 ID: 2  평점: 1\n",
      "추천된 아이템 ID: 3  평점: 1\n",
      "추천된 아이템 ID: 4  평점: 1\n",
      "추천된 아이템 ID: 5  평점: 1\n",
      "추천된 아이템 ID: 6  평점: 1\n",
      "추천된 아이템 ID: 7  평점: 1\n",
      "추천된 아이템 ID: 8  평점: 1\n",
      "추천된 아이템 ID: 9  평점: 1\n",
      "추천된 아이템 ID: 10  평점: 1\n",
      "추천된 아이템 ID: 11  평점: 1\n",
      "추천된 아이템 ID: 12  평점: 1\n",
      "추천된 아이템 ID: 13  평점: 1\n",
      "추천된 아이템 ID: 14  평점: 1\n",
      "추천된 아이템 ID: 15  평점: 1\n",
      "추천된 아이템 ID: 16  평점: 1\n",
      "추천된 아이템 ID: 17  평점: 1\n",
      "추천된 아이템 ID: 18  평점: 1\n",
      "추천된 아이템 ID: 19  평점: 1\n",
      "추천된 아이템 ID: 20  평점: 1\n",
      "추천된 아이템 ID: 21  평점: 1\n",
      "추천된 아이템 ID: 22  평점: 1\n",
      "추천된 아이템 ID: 23  평점: 1\n",
      "추천된 아이템 ID: 24  평점: 1\n",
      "추천된 아이템 ID: 25  평점: 1\n",
      "추천된 아이템 ID: 26  평점: 1\n",
      "추천된 아이템 ID: 27  평점: 1\n",
      "추천된 아이템 ID: 28  평점: 1\n",
      "추천된 아이템 ID: 29  평점: 1\n",
      "추천된 아이템 ID: 30  평점: 1\n",
      "추천된 아이템 ID: 31  평점: 1\n",
      "추천된 아이템 ID: 32  평점: 1\n",
      "추천된 아이템 ID: 33  평점: 1\n",
      "추천된 아이템 ID: 34  평점: 1\n",
      "추천된 아이템 ID: 35  평점: 1\n",
      "추천된 아이템 ID: 36  평점: 1\n",
      "추천된 아이템 ID: 37  평점: 1\n",
      "추천된 아이템 ID: 38  평점: 1\n",
      "추천된 아이템 ID: 39  평점: 1\n",
      "추천된 아이템 ID: 40  평점: 1\n",
      "추천된 아이템 ID: 41  평점: 1\n",
      "추천된 아이템 ID: 42  평점: 1\n",
      "추천된 아이템 ID: 43  평점: 1\n",
      "추천된 아이템 ID: 44  평점: 1\n",
      "추천된 아이템 ID: 45  평점: 1\n",
      "추천된 아이템 ID: 46  평점: 1\n",
      "추천된 아이템 ID: 47  평점: 1\n",
      "추천된 아이템 ID: 48  평점: 1\n",
      "추천된 아이템 ID: 49  평점: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD\n",
    "\n",
    "# 데이터를 불러오기 위한 Reader 객체를 생성합니다.\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "\n",
    "# filtered_train_df 데이터프레임을 Surprise의 Dataset 객체로 변환합니다.\n",
    "trainset = Dataset.load_from_df(filtered_train_df[['session_id', 'outfit_id', 'rating']].fillna(0), reader)\n",
    "\n",
    "# DatasetAutoFolds를 Dataset으로 변환합니다.\n",
    "trainset = trainset.build_full_trainset()\n",
    "\n",
    "# SVD 모델을 생성하고 학습합니다.\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# 모든 아이디에 대해 상위 n개의 아이템을 추천합니다.\n",
    "items_to_recommend = 50  # 추천할 아이템 개수\n",
    "\n",
    "# 모든 사용자와 아이템의 id를 가져옵니다.\n",
    "all_users = trainset.all_users()\n",
    "all_items = set(trainset.all_items())  # Convert all_items to a set\n",
    "\n",
    "# 새로운 사용자 ID (실제 사용자 ID로 대체해야 합니다.)\n",
    "new_user_id = 101\n",
    "\n",
    "# 새로운 사용자가 이미 평가한 아이템의 outfit_id를 가져옵니다.\n",
    "try:\n",
    "    # 사용자의 outfit_id를 가져옵니다.\n",
    "    user_items_index = trainset.ur[trainset.to_inner_uid(new_user_id)]\n",
    "    user_items = [filtered_train_df.at[trainset.to_raw_uid(new_user_id), 'outfit_id'] for (item_id, _) in user_items_index]\n",
    "except ValueError:\n",
    "    print(f\"사용자 ID {new_user_id}는 기존 데이터에 존재하지 않습니다. 유효한 사용자 ID로 대체해주세요.\")\n",
    "    # 다른 유효한 사용자 ID로 대체해야 합니다.\n",
    "\n",
    "# 모든 아이템 중에서 새로운 사용자가 평가하지 않은 아이템들을 구합니다.\n",
    "items_to_predict = list(all_items - set(user_items))\n",
    "\n",
    "# 예측한 평점을 기준으로 상위 n개의 아이템을 추천합니다.\n",
    "predictions = [(iid, model.predict(new_user_id, iid).est) for iid in items_to_predict]\n",
    "\n",
    "# 추천된 아이템 출력\n",
    "print(f\"새로운 사용자 ID: {new_user_id}\")\n",
    "for item_id, score in sorted(predictions, key=lambda x: x[1], reverse=True)[:items_to_recommend]:\n",
    "    print(f'추천된 아이템 ID: {item_id}  평점: {score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting surprise\n",
      "  Using cached surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
      "Collecting scikit-surprise\n",
      "  Using cached scikit-surprise-1.1.3.tar.gz (771 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in /opt/conda/envs/jun/lib/python3.9/site-packages (from scikit-surprise->surprise) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/jun/lib/python3.9/site-packages (from scikit-surprise->surprise) (1.22.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/envs/jun/lib/python3.9/site-packages (from scikit-surprise->surprise) (1.7.3)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp39-cp39-linux_x86_64.whl size=1213284 sha256=a4f9f5b8b70f2a145800cbb734cd2634f2bb5c301625cb6f2a1aa97e3af38ddd\n",
      "  Stored in directory: /opt/ml/.cache/pip/wheels/c6/3a/46/9b17b3512bdf283c6cb84f59929cdd5199d4e754d596d22784\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: scikit-surprise, surprise\n",
      "Successfully installed scikit-surprise-1.1.3 surprise-0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outfit_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>reporter</th>\n",
       "      <th>tags</th>\n",
       "      <th>brands</th>\n",
       "      <th>region</th>\n",
       "      <th>occupation</th>\n",
       "      <th>style</th>\n",
       "      <th>date</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>tags_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64453</td>\n",
       "      <td>여성</td>\n",
       "      <td>NaN</td>\n",
       "      <td>화이트 컬러의 베이프 반팔 티셔츠와 와이드 데님 팬츠를 매칭한 룩입니다.</td>\n",
       "      <td>반팔 티셔츠,가을,스트릿</td>\n",
       "      <td>unknown</td>\n",
       "      <td>부산/경남</td>\n",
       "      <td>전문직/프리랜서</td>\n",
       "      <td>스트릿</td>\n",
       "      <td>2020-09-17 00:00:00.000000</td>\n",
       "      <td>가을</td>\n",
       "      <td>2020</td>\n",
       "      <td>반팔 티셔츠,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68758</td>\n",
       "      <td>여성</td>\n",
       "      <td>19.0</td>\n",
       "      <td>데님 스커트와 패딩 재킷을 매칭한 룩입니다.</td>\n",
       "      <td>스니커즈,봄,캐주얼,나이키</td>\n",
       "      <td>나이키</td>\n",
       "      <td>홍대/신촌</td>\n",
       "      <td>학생</td>\n",
       "      <td>캐주얼</td>\n",
       "      <td>2021-02-24 00:00:00.000000</td>\n",
       "      <td>봄</td>\n",
       "      <td>2021</td>\n",
       "      <td>스니커즈,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71478</td>\n",
       "      <td>여성</td>\n",
       "      <td>22.0</td>\n",
       "      <td>블랙 컬러의 스커트와 화이트 셔츠를 매칭한 룩입니다.</td>\n",
       "      <td>여성,셔츠,레더 스커트,워커,여름,캐주얼</td>\n",
       "      <td>unknown</td>\n",
       "      <td>홍대/신촌</td>\n",
       "      <td>사무직</td>\n",
       "      <td>캐주얼</td>\n",
       "      <td>2021-06-01 00:00:00.000000</td>\n",
       "      <td>여름</td>\n",
       "      <td>2021</td>\n",
       "      <td>,셔츠,레더 스커트,워커,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71480</td>\n",
       "      <td>여성</td>\n",
       "      <td>25.0</td>\n",
       "      <td>블랙 컬러의 슬리브리스 탑과 나이키 덩크 하이 스니커즈를 매칭한 룩입니다.</td>\n",
       "      <td>여성,슬리브리스,트랙 팬츠,스니커즈,숄더 백,나이키,여름,로맨틱</td>\n",
       "      <td>나이키</td>\n",
       "      <td>홍대/신촌</td>\n",
       "      <td>학생</td>\n",
       "      <td>로맨틱</td>\n",
       "      <td>2021-06-01 00:00:00.000000</td>\n",
       "      <td>여름</td>\n",
       "      <td>2021</td>\n",
       "      <td>,슬리브리스,트랙 팬츠,스니커즈,숄더 백,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71482</td>\n",
       "      <td>남성</td>\n",
       "      <td>24.0</td>\n",
       "      <td>블랙 컬러의 베스트와 나이키 덩크 '범고래' 를 매칭한\\n 룩입니다.</td>\n",
       "      <td>남성,비니,베스트,크로스 백,데님 팬츠,스니커즈,나이키,여름,스트릿</td>\n",
       "      <td>나이키</td>\n",
       "      <td>홍대/신촌</td>\n",
       "      <td>패션업</td>\n",
       "      <td>스트릿</td>\n",
       "      <td>2021-06-01 00:00:00.000000</td>\n",
       "      <td>여름</td>\n",
       "      <td>2021</td>\n",
       "      <td>,비니,베스트,크로스 백,데님 팬츠,스니커즈,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10424</th>\n",
       "      <td>92177</td>\n",
       "      <td>남성</td>\n",
       "      <td>21.0</td>\n",
       "      <td>데님 반소매 셔츠와 블랙 데님 와이드 팬츠, 아디다스 스니커즈를 매치한 룩입니다.</td>\n",
       "      <td>여름,스트릿</td>\n",
       "      <td>unknown</td>\n",
       "      <td>홍대/신촌</td>\n",
       "      <td>학생</td>\n",
       "      <td>스트릿</td>\n",
       "      <td>2023-06-29 00:00:00.000000</td>\n",
       "      <td>여름</td>\n",
       "      <td>2023</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10425</th>\n",
       "      <td>92178</td>\n",
       "      <td>여성</td>\n",
       "      <td>21.0</td>\n",
       "      <td>화이트 컬러의 셔츠, 미니 스커트와 워커를 매치한 룩입니다.</td>\n",
       "      <td>여름,걸리시</td>\n",
       "      <td>unknown</td>\n",
       "      <td>홍대/신촌</td>\n",
       "      <td>학생</td>\n",
       "      <td>걸리시</td>\n",
       "      <td>2023-06-29 00:00:00.000000</td>\n",
       "      <td>여름</td>\n",
       "      <td>2023</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10426</th>\n",
       "      <td>92179</td>\n",
       "      <td>여성</td>\n",
       "      <td>19.0</td>\n",
       "      <td>그레이 컬러의 반소매 티셔츠, 화이트 컬러의 7부 팬츠를 매치한 룩입니다.</td>\n",
       "      <td>여름,스트릿</td>\n",
       "      <td>unknown</td>\n",
       "      <td>홍대/신촌</td>\n",
       "      <td>학생</td>\n",
       "      <td>스트릿</td>\n",
       "      <td>2023-06-29 00:00:00.000000</td>\n",
       "      <td>여름</td>\n",
       "      <td>2023</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10427</th>\n",
       "      <td>92181</td>\n",
       "      <td>여성</td>\n",
       "      <td>21.0</td>\n",
       "      <td>블랙 컬러의 시스루 카디건과 슬리브리스, 데님 팬츠를 매칭한 룩입니다.</td>\n",
       "      <td>여름,스트릿</td>\n",
       "      <td>unknown</td>\n",
       "      <td>홍대/신촌</td>\n",
       "      <td>학생</td>\n",
       "      <td>스트릿</td>\n",
       "      <td>2023-06-29 00:00:00.000000</td>\n",
       "      <td>여름</td>\n",
       "      <td>2023</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10428</th>\n",
       "      <td>92182</td>\n",
       "      <td>여성</td>\n",
       "      <td>21.0</td>\n",
       "      <td>블랙 컬러의 원피스, 첼시 부츠를 매치한 룩입니다.</td>\n",
       "      <td>여름,걸리시</td>\n",
       "      <td>unknown</td>\n",
       "      <td>홍대/신촌</td>\n",
       "      <td>학생</td>\n",
       "      <td>걸리시</td>\n",
       "      <td>2023-06-29 00:00:00.000000</td>\n",
       "      <td>여름</td>\n",
       "      <td>2023</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10429 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       outfit_id gender   age                                       reporter  \\\n",
       "0          64453     여성   NaN       화이트 컬러의 베이프 반팔 티셔츠와 와이드 데님 팬츠를 매칭한 룩입니다.   \n",
       "1          68758     여성  19.0                       데님 스커트와 패딩 재킷을 매칭한 룩입니다.   \n",
       "2          71478     여성  22.0                  블랙 컬러의 스커트와 화이트 셔츠를 매칭한 룩입니다.   \n",
       "3          71480     여성  25.0      블랙 컬러의 슬리브리스 탑과 나이키 덩크 하이 스니커즈를 매칭한 룩입니다.   \n",
       "4          71482     남성  24.0         블랙 컬러의 베스트와 나이키 덩크 '범고래' 를 매칭한\\n 룩입니다.   \n",
       "...          ...    ...   ...                                            ...   \n",
       "10424      92177     남성  21.0  데님 반소매 셔츠와 블랙 데님 와이드 팬츠, 아디다스 스니커즈를 매치한 룩입니다.   \n",
       "10425      92178     여성  21.0              화이트 컬러의 셔츠, 미니 스커트와 워커를 매치한 룩입니다.   \n",
       "10426      92179     여성  19.0      그레이 컬러의 반소매 티셔츠, 화이트 컬러의 7부 팬츠를 매치한 룩입니다.   \n",
       "10427      92181     여성  21.0        블랙 컬러의 시스루 카디건과 슬리브리스, 데님 팬츠를 매칭한 룩입니다.   \n",
       "10428      92182     여성  21.0                   블랙 컬러의 원피스, 첼시 부츠를 매치한 룩입니다.   \n",
       "\n",
       "                                        tags   brands region occupation style  \\\n",
       "0                              반팔 티셔츠,가을,스트릿  unknown  부산/경남   전문직/프리랜서   스트릿   \n",
       "1                             스니커즈,봄,캐주얼,나이키      나이키  홍대/신촌         학생   캐주얼   \n",
       "2                     여성,셔츠,레더 스커트,워커,여름,캐주얼  unknown  홍대/신촌        사무직   캐주얼   \n",
       "3        여성,슬리브리스,트랙 팬츠,스니커즈,숄더 백,나이키,여름,로맨틱      나이키  홍대/신촌         학생   로맨틱   \n",
       "4      남성,비니,베스트,크로스 백,데님 팬츠,스니커즈,나이키,여름,스트릿      나이키  홍대/신촌        패션업   스트릿   \n",
       "...                                      ...      ...    ...        ...   ...   \n",
       "10424                                 여름,스트릿  unknown  홍대/신촌         학생   스트릿   \n",
       "10425                                 여름,걸리시  unknown  홍대/신촌         학생   걸리시   \n",
       "10426                                 여름,스트릿  unknown  홍대/신촌         학생   스트릿   \n",
       "10427                                 여름,스트릿  unknown  홍대/신촌         학생   스트릿   \n",
       "10428                                 여름,걸리시  unknown  홍대/신촌         학생   걸리시   \n",
       "\n",
       "                             date season  year                        tags_  \n",
       "0      2020-09-17 00:00:00.000000     가을  2020                     반팔 티셔츠,,  \n",
       "1      2021-02-24 00:00:00.000000      봄  2021                      스니커즈,,,  \n",
       "2      2021-06-01 00:00:00.000000     여름  2021              ,셔츠,레더 스커트,워커,,  \n",
       "3      2021-06-01 00:00:00.000000     여름  2021    ,슬리브리스,트랙 팬츠,스니커즈,숄더 백,,,  \n",
       "4      2021-06-01 00:00:00.000000     여름  2021  ,비니,베스트,크로스 백,데님 팬츠,스니커즈,,,  \n",
       "...                           ...    ...   ...                          ...  \n",
       "10424  2023-06-29 00:00:00.000000     여름  2023                            ,  \n",
       "10425  2023-06-29 00:00:00.000000     여름  2023                            ,  \n",
       "10426  2023-06-29 00:00:00.000000     여름  2023                            ,  \n",
       "10427  2023-06-29 00:00:00.000000     여름  2023                            ,  \n",
       "10428  2023-06-29 00:00:00.000000     여름  2023                            ,  \n",
       "\n",
       "[10429 rows x 13 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outfit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightfm.data import Dataset\n",
    "from scipy.io import mmwrite\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightfm import LightFM\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming train_df and outfit_df are already defined\n",
    "\n",
    "# session_id와 outfit_id를 라벨 인코딩하여 인덱스 형태로 변환\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['session_id'] = label_encoder.fit_transform(train_df['session_id'])\n",
    "ratings_source = [(train_df['session_id'][i], train_df['outfit_id'][i]) for i in range(train_df.shape[0])]\n",
    "\n",
    "# Keep only the outfit_ids that are present in train_df\n",
    "common_outfit_ids = train_df['outfit_id'].unique()\n",
    "outfit_df = outfit_df[outfit_df['outfit_id'].isin(common_outfit_ids)]\n",
    "\n",
    "outfit_df = outfit_df[['outfit_id', 'gender', 'age', 'style', 'season', 'year']]\n",
    "outfit_df = outfit_df.fillna('unknown')  # NaN을 'unknown'으로 대체\n",
    "\n",
    "# Create item features list using iterrows()\n",
    "item_features_source = []\n",
    "for index, row in outfit_df.iterrows():\n",
    "    item_id = row['outfit_id']\n",
    "    item_features = [row['gender'], row['age'], row['style'], row['season'], row['year']]\n",
    "    item_features_source.append((item_id, item_features))\n",
    "\n",
    "\n",
    "\n",
    "# Dataset 객체 생성\n",
    "dataset = Dataset()\n",
    "\n",
    "# 사용자와 아이템 라벨을 fit() 메서드를 통해 매핑\n",
    "dataset.fit(users=train_df['session_id'].unique(),\n",
    "            items=train_df['outfit_id'].unique(),\n",
    "            item_features=outfit_df[outfit_df.columns[1:]].values.flatten()\n",
    "            )\n",
    "\n",
    "interactions, weights = dataset.build_interactions(ratings_source)\n",
    "item_features = dataset.build_item_features(item_features_source)\n",
    "\n",
    "# Save\n",
    "mmwrite('../../data/train-test/interactions.mtx', interactions)\n",
    "mmwrite('../../data/train-test/item_features.mtx', item_features)\n",
    "mmwrite('../../data/train-test/weights.mtx', weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train, Test data\n",
    "train_interactions, test_interactions, train_weights, test_weights = train_test_split(\n",
    "    interactions, weights, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to COO format\n",
    "train_interactions = train_interactions.tocsr().tocoo()\n",
    "test_interactions = test_interactions.tocsr().tocoo()\n",
    "train_weights = train_weights.tocoo()\n",
    "test_weights = test_weights.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, hp, tpe, Trials\n",
    "\n",
    "# Define Search Space\n",
    "trials = Trials()\n",
    "space = [hp.choice('no_components', range(10, 50, 10)),\n",
    "         hp.uniform('learning_rate', 0.01, 0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incorrect number of features in user_features",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m# Call the objective function and pass the data\u001b[39;00m\n\u001b[1;32m     26\u001b[0m params \u001b[39m=\u001b[39m (\u001b[39m10\u001b[39m, \u001b[39m0.01\u001b[39m)  \u001b[39m# Replace with your desired parameter values\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m objective_result \u001b[39m=\u001b[39m objective(params, train_interactions, test_interactions, train_weights, test_weights)\n",
      "Cell \u001b[0;32mIn[53], line 18\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(params, train_interactions, test_interactions, train_weights, test_weights)\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[39m=\u001b[39m LightFM(no_components\u001b[39m=\u001b[39mno_components,\n\u001b[1;32m      6\u001b[0m                 learning_schedule\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madagrad\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                 loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mwarp\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m                 learning_rate\u001b[39m=\u001b[39mlearning_rate,\n\u001b[1;32m      9\u001b[0m                 random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     11\u001b[0m model\u001b[39m.\u001b[39mfit(train_interactions,\n\u001b[1;32m     12\u001b[0m           item_features\u001b[39m=\u001b[39mitem_features,\n\u001b[1;32m     13\u001b[0m           sample_weight\u001b[39m=\u001b[39mtrain_weights,\n\u001b[1;32m     14\u001b[0m           epochs\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[1;32m     15\u001b[0m           verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m           user_features\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m---> 18\u001b[0m test_precision \u001b[39m=\u001b[39m precision_at_k(model, test_interactions, k\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, item_features\u001b[39m=\u001b[39;49mitem_features, user_features\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     19\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mno_components: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, learning_rate: \u001b[39m\u001b[39m{:.5f}\u001b[39;00m\u001b[39m, precision: \u001b[39m\u001b[39m{:.5f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     20\u001b[0m     no_components, learning_rate, test_precision))\n\u001b[1;32m     22\u001b[0m \u001b[39m# Return negative precision as we want to maximize it using the optimizer\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/jun/lib/python3.9/site-packages/lightfm/evaluation.py:71\u001b[0m, in \u001b[0;36mprecision_at_k\u001b[0;34m(model, test_interactions, train_interactions, k, user_features, item_features, preserve_rows, num_threads, check_intersections)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mif\u001b[39;00m num_threads \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     69\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNumber of threads must be 1 or larger.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 71\u001b[0m ranks \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict_rank(\n\u001b[1;32m     72\u001b[0m     test_interactions,\n\u001b[1;32m     73\u001b[0m     train_interactions\u001b[39m=\u001b[39;49mtrain_interactions,\n\u001b[1;32m     74\u001b[0m     user_features\u001b[39m=\u001b[39;49muser_features,\n\u001b[1;32m     75\u001b[0m     item_features\u001b[39m=\u001b[39;49mitem_features,\n\u001b[1;32m     76\u001b[0m     num_threads\u001b[39m=\u001b[39;49mnum_threads,\n\u001b[1;32m     77\u001b[0m     check_intersections\u001b[39m=\u001b[39;49mcheck_intersections,\n\u001b[1;32m     78\u001b[0m )\n\u001b[1;32m     80\u001b[0m ranks\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mless(ranks\u001b[39m.\u001b[39mdata, k, ranks\u001b[39m.\u001b[39mdata)\n\u001b[1;32m     82\u001b[0m precision \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqueeze(np\u001b[39m.\u001b[39marray(ranks\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))) \u001b[39m/\u001b[39m k\n",
      "File \u001b[0;32m/opt/conda/envs/jun/lib/python3.9/site-packages/lightfm/lightfm.py:957\u001b[0m, in \u001b[0;36mLightFM.predict_rank\u001b[0;34m(self, test_interactions, train_interactions, item_features, user_features, num_threads, check_intersections)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIncorrect number of features in item_features\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    956\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_features\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_embeddings\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[0;32m--> 957\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIncorrect number of features in user_features\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    959\u001b[0m test_interactions \u001b[39m=\u001b[39m test_interactions\u001b[39m.\u001b[39mtocsr()\n\u001b[1;32m    960\u001b[0m test_interactions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_to_cython_dtype(test_interactions)\n",
      "\u001b[0;31mValueError\u001b[0m: Incorrect number of features in user_features"
     ]
    }
   ],
   "source": [
    "# Define Objective Function\n",
    "def objective(params, train_interactions, test_interactions, train_weights, test_weights):\n",
    "    no_components, learning_rate = params\n",
    "\n",
    "    model = LightFM(no_components=no_components,\n",
    "                    learning_schedule='adagrad',\n",
    "                    loss='warp',\n",
    "                    learning_rate=learning_rate,\n",
    "                    random_state=0)\n",
    "\n",
    "    model.fit(train_interactions,\n",
    "              item_features=item_features,\n",
    "              sample_weight=train_weights,\n",
    "              epochs=3,\n",
    "              verbose=False,\n",
    "              user_features=None)\n",
    "\n",
    "    test_precision = precision_at_k(model, test_interactions, k=5, item_features=item_features, user_features=None).mean()\n",
    "    print(\"no_components: {}, learning_rate: {:.5f}, precision: {:.5f}\".format(\n",
    "        no_components, learning_rate, test_precision))\n",
    "    \n",
    "    # Return negative precision as we want to maximize it using the optimizer\n",
    "    return -test_precision\n",
    "\n",
    "# Call the objective function and pass the data\n",
    "params = (10, 0.01)  # Replace with your desired parameter values\n",
    "objective_result = objective(params, train_interactions, test_interactions, train_weights, test_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "objective() takes 1 positional argument but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m objective_result \u001b[39m=\u001b[39m objective((\u001b[39m10\u001b[39;49m, \u001b[39m0.01\u001b[39;49m), train_interactions, test_interactions, train_weights, test_weights)\n",
      "\u001b[0;31mTypeError\u001b[0m: objective() takes 1 positional argument but 5 were given"
     ]
    }
   ],
   "source": [
    "# objective_result = objective((10, 0.01), train_interactions, test_interactions, train_weights, test_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Incorrect number of features in user_features\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Incorrect number of features in user_features",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_params \u001b[39m=\u001b[39m fmin(fn\u001b[39m=\u001b[39;49mobjective, space\u001b[39m=\u001b[39;49mspace, algo\u001b[39m=\u001b[39;49mtpe\u001b[39m.\u001b[39;49msuggest, max_evals\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, trials\u001b[39m=\u001b[39;49mtrials)\n",
      "File \u001b[0;32m/opt/conda/envs/jun/lib/python3.9/site-packages/hyperopt/fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    537\u001b[0m     fn \u001b[39m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[1;32m    539\u001b[0m \u001b[39mif\u001b[39;00m allow_trials_fmin \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(trials, \u001b[39m\"\u001b[39m\u001b[39mfmin\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[39mreturn\u001b[39;00m trials\u001b[39m.\u001b[39;49mfmin(\n\u001b[1;32m    541\u001b[0m         fn,\n\u001b[1;32m    542\u001b[0m         space,\n\u001b[1;32m    543\u001b[0m         algo\u001b[39m=\u001b[39;49malgo,\n\u001b[1;32m    544\u001b[0m         max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[1;32m    545\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    546\u001b[0m         loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[1;32m    547\u001b[0m         max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[1;32m    548\u001b[0m         rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[1;32m    549\u001b[0m         pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[1;32m    550\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    551\u001b[0m         catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[1;32m    552\u001b[0m         return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[1;32m    553\u001b[0m         show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[1;32m    554\u001b[0m         early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[1;32m    555\u001b[0m         trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[1;32m    556\u001b[0m     )\n\u001b[1;32m    558\u001b[0m \u001b[39mif\u001b[39;00m trials \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[0;32m/opt/conda/envs/jun/lib/python3.9/site-packages/hyperopt/base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[39m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[39m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[39m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfmin\u001b[39;00m \u001b[39mimport\u001b[39;00m fmin\n\u001b[0;32m--> 671\u001b[0m \u001b[39mreturn\u001b[39;00m fmin(\n\u001b[1;32m    672\u001b[0m     fn,\n\u001b[1;32m    673\u001b[0m     space,\n\u001b[1;32m    674\u001b[0m     algo\u001b[39m=\u001b[39;49malgo,\n\u001b[1;32m    675\u001b[0m     max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[1;32m    676\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    677\u001b[0m     loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[1;32m    678\u001b[0m     trials\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    679\u001b[0m     rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[1;32m    680\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    681\u001b[0m     max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[1;32m    682\u001b[0m     allow_trials_fmin\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# -- prevent recursion\u001b[39;49;00m\n\u001b[1;32m    683\u001b[0m     pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[1;32m    684\u001b[0m     catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[1;32m    685\u001b[0m     return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[1;32m    686\u001b[0m     show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[1;32m    687\u001b[0m     early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[1;32m    688\u001b[0m     trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[1;32m    689\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/jun/lib/python3.9/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[39m.\u001b[39mcatch_eval_exceptions \u001b[39m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[39m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m rval\u001b[39m.\u001b[39;49mexhaust()\n\u001b[1;32m    588\u001b[0m \u001b[39mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trials\u001b[39m.\u001b[39mtrials) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/jun/lib/python3.9/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaust\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals \u001b[39m-\u001b[39;49m n_done, block_until_done\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masynchronous)\n\u001b[1;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/jun/lib/python3.9/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[39m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserial_evaluate()\n\u001b[1;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials_save_file \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/jun/lib/python3.9/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mCtrl(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials, current_trial\u001b[39m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomain\u001b[39m.\u001b[39;49mevaluate(spec, ctrl)\n\u001b[1;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mjob exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[0;32m/opt/conda/envs/jun/lib/python3.9/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[39m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[39m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[39m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[39m=\u001b[39m pyll\u001b[39m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[39m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(pyll_rval)\n\u001b[1;32m    894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rval, (\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(rval), \u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[0;32mIn[49], line 18\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[39m=\u001b[39m LightFM(no_components\u001b[39m=\u001b[39mno_components,\n\u001b[1;32m      6\u001b[0m                 learning_schedule\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madagrad\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                 loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mwarp\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m                 learning_rate\u001b[39m=\u001b[39mlearning_rate,\n\u001b[1;32m      9\u001b[0m                 random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m     11\u001b[0m model\u001b[39m.\u001b[39mfit(train_interactions,\n\u001b[1;32m     12\u001b[0m           item_features\u001b[39m=\u001b[39mitem_features,\n\u001b[1;32m     13\u001b[0m           sample_weight\u001b[39m=\u001b[39mtrain_weights,\n\u001b[1;32m     14\u001b[0m           epochs\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[1;32m     15\u001b[0m           verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m           user_features\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m---> 18\u001b[0m test_precision \u001b[39m=\u001b[39m precision_at_k(model, test_interactions, k\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, item_features\u001b[39m=\u001b[39;49mitem_features, user_features\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     19\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mno_components: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, learning_rate: \u001b[39m\u001b[39m{:.5f}\u001b[39;00m\u001b[39m, precision: \u001b[39m\u001b[39m{:.5f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     20\u001b[0m     no_components, learning_rate, test_precision))\n\u001b[1;32m     22\u001b[0m \u001b[39m# Return negative precision as we want to maximize it using the optimizer\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/jun/lib/python3.9/site-packages/lightfm/evaluation.py:71\u001b[0m, in \u001b[0;36mprecision_at_k\u001b[0;34m(model, test_interactions, train_interactions, k, user_features, item_features, preserve_rows, num_threads, check_intersections)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mif\u001b[39;00m num_threads \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     69\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNumber of threads must be 1 or larger.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 71\u001b[0m ranks \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict_rank(\n\u001b[1;32m     72\u001b[0m     test_interactions,\n\u001b[1;32m     73\u001b[0m     train_interactions\u001b[39m=\u001b[39;49mtrain_interactions,\n\u001b[1;32m     74\u001b[0m     user_features\u001b[39m=\u001b[39;49muser_features,\n\u001b[1;32m     75\u001b[0m     item_features\u001b[39m=\u001b[39;49mitem_features,\n\u001b[1;32m     76\u001b[0m     num_threads\u001b[39m=\u001b[39;49mnum_threads,\n\u001b[1;32m     77\u001b[0m     check_intersections\u001b[39m=\u001b[39;49mcheck_intersections,\n\u001b[1;32m     78\u001b[0m )\n\u001b[1;32m     80\u001b[0m ranks\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mless(ranks\u001b[39m.\u001b[39mdata, k, ranks\u001b[39m.\u001b[39mdata)\n\u001b[1;32m     82\u001b[0m precision \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqueeze(np\u001b[39m.\u001b[39marray(ranks\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))) \u001b[39m/\u001b[39m k\n",
      "File \u001b[0;32m/opt/conda/envs/jun/lib/python3.9/site-packages/lightfm/lightfm.py:957\u001b[0m, in \u001b[0;36mLightFM.predict_rank\u001b[0;34m(self, test_interactions, train_interactions, item_features, user_features, num_threads, check_intersections)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIncorrect number of features in item_features\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    956\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_features\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_embeddings\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[0;32m--> 957\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIncorrect number of features in user_features\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    959\u001b[0m test_interactions \u001b[39m=\u001b[39m test_interactions\u001b[39m.\u001b[39mtocsr()\n\u001b[1;32m    960\u001b[0m test_interactions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_to_cython_dtype(test_interactions)\n",
      "\u001b[0;31mValueError\u001b[0m: Incorrect number of features in user_features"
     ]
    }
   ],
   "source": [
    "best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=10, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
